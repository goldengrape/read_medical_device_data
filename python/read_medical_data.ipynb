{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 通用读取函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据每个设备的json描述文件, 读取csv数据文件中的数据. \n",
    "\n",
    "json描述文件: \n",
    "```json\n",
    "{\"sep\": csv文件的分隔符号\n",
    " \"category\": \n",
    "   {\n",
    "   \"数据类1\": {\"location\": 数据块位置, \"dtype\": 数据类型}, \n",
    "   \"数据类2\": {\"location\": \"A1..B3\", \"dtype\": \"numeric\"}, \n",
    "   ...\n",
    "   }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-14T09:10:39.349332Z",
     "start_time": "2018-05-14T09:10:37.978480Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from dlm import dlmread, dlmread_df\n",
    "from dlm import cellblock2num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-14T09:10:39.375424Z",
     "start_time": "2018-05-14T09:10:39.352469Z"
    }
   },
   "outputs": [],
   "source": [
    "def max_column(category_dict):\n",
    "    # 确定文件的最大列数. \n",
    "    # 形如\n",
    "    # 1, 2, 3\n",
    "    # 1, 2, 3, 4\n",
    "    # 这样的csv文件, 直接读取会出错, 需要设定所有的列名\n",
    "    borders=[cellblock2num(v[\"location\"])[3] for k,v in category_dict.items() ]\n",
    "    return max(borders)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-14T09:10:39.409850Z",
     "start_time": "2018-05-14T09:10:39.388133Z"
    }
   },
   "outputs": [],
   "source": [
    "def open_data_file(data_file,json_data_file):\n",
    "    with open(json_data_file, 'r') as f:\n",
    "        json_data = json.load(f)\n",
    "    sep=json_data[\"sep\"]\n",
    "    category_dict=json_data[\"category\"]\n",
    "    max_col=max_column(category_dict)\n",
    "    df=pd.read_csv(data_file,sep=sep,names=range(max_col),header=None)\n",
    "    return df,category_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-14T09:10:39.491200Z",
     "start_time": "2018-05-14T09:10:39.419908Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_medical_data_one_by_one(data_file,catalog,json_data_file):\n",
    "    '''\n",
    "    从datafile中读取category所定义的数据块, 以pandas DataFrame的格式返回数据. \n",
    "    - datafile: 需要读取的数据文件, 例如\"病人ID.csv\"\n",
    "    - category:  需要读取的数据块类型, 例如角膜地形图前表面数据\"FRONT\"\n",
    "    - jsondatafile: 用于描述设备文件的json文件, 规定了每个类型所对应的数据块\n",
    "    '''\n",
    "    \n",
    "    catalog_dict= pd.read_json(json_data_file,typ = 'series')\n",
    "    data=[]\n",
    "    with open(data_file,'rt') as f: \n",
    "#     if True:\n",
    "#         f=data_file\n",
    "        if type(catalog)==str:\n",
    "            if catalog.lower() != \"all\":\n",
    "                data=dlmread(f,';',catalog_dict[catalog])\n",
    "            elif catalog.lower() == \"all\":\n",
    "                catalog=catalog_dict.keys()\n",
    "                data={cat:dlmread(f,';',catalog_dict[cat]) for cat in catalog}\n",
    "#         elif type(catalog)==list:\n",
    "        else:\n",
    "            print(\"list!\")\n",
    "            data={cat:dlmread(f,';',catalog_dict[cat]) for cat in catalog}\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-14T09:10:39.547054Z",
     "start_time": "2018-05-14T09:10:39.495900Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_medical_data(data_file,category,json_data_file):\n",
    "    '''\n",
    "    从datafile中读取category所定义的数据块, 以pandas DataFrame的格式返回数据. \n",
    "    - datafile: 需要读取的数据文件, 例如\"病人ID.csv\"\n",
    "    - category:  需要读取的数据块类型, 例如角膜地形图前表面数据\"FRONT\"\n",
    "    - jsondatafile: 用于描述设备文件的json文件, 规定了每个类型所对应的数据块\n",
    "    如果提取的是多个数据块类型, 返回字典\n",
    "    '''\n",
    "    # 读取文件\n",
    "    df, category_dict=open_data_file(data_file,json_data_file)\n",
    "    # category可以是一个类别, 也可以是all描述为所有类别, 也可以是一个列表\n",
    "    if type(category)==str:\n",
    "        if category.lower() != \"all\": # 如果只是一个类别\n",
    "            data=dlmread_df(df,category_dict[category][\"location\"],category_dict[category][\"dtype\"])\n",
    "        elif category.lower() == \"all\": # 如果是all, 要提取所有类别\n",
    "            category=category_dict.keys()\n",
    "            data={cat:dlmread_df(df,category_dict[cat][\"location\"],category_dict[cat][\"dtype\"]) for cat in category}\n",
    "    elif type(category)==list: \n",
    "#     else:\n",
    "        data={cat:dlmread_df(df,category_dict[cat][\"location\"],category_dict[cat][\"dtype\"]) \n",
    "              for cat in category }\n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-14T09:10:39.618862Z",
     "start_time": "2018-05-14T09:10:39.555096Z"
    }
   },
   "outputs": [],
   "source": [
    "# 测试用: \n",
    "if __name__==\"__main__\" and True:\n",
    "    dpath=os.path.join('..','testdata')\n",
    "    dname='HRT001.csv'\n",
    "\n",
    "    datafilename=os.path.join(dpath,dname)\n",
    "\n",
    "#     category='CornealThickness'\n",
    "#     category=[\"TangentialAnterior\",\"TangentialPosterior\"]\n",
    "    category=['DOB', 'sex', 'date', 'Asymmetry_data']\n",
    "    \n",
    "    jpath=os.path.join(\"..\",\"medical_device_data\")\n",
    "    jname=\"HRT.json\"\n",
    "    jsonfilename=os.path.join(jpath,jname)\n",
    "    data=read_medical_data(datafilename,category,jsonfilename)\n",
    "#     print(data[\"OS_data\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 根据分类文件读取数据文件序列"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 分类文件class.csv: \n",
    "\n",
    "|class\t|HRT\t|humphrey|\n",
    "|:--|:--|:--|\n",
    "|OS_glaucoma\t|HRT001.csv\t|HFA001.csv|\n",
    "|OD_glaucoma\t|HRT002.csv\t|HFA002.csv|\n",
    "|OS_normal\t|HRT003.csv\t|HFA003.csv|\n",
    "|OD_normal\t|HRT004.csv\t|HFA004.csv|\n",
    "\n",
    "第一列说明分类, 可以是数字或字符, 可以有多个类别\n",
    "\n",
    "之后的列是不同检查的设备名称和文件列表. 设备仅支持带有json文件说明的 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 数据类别选取文件analysis_catagory.csv, \n",
    "\n",
    "需要用户手动编辑, 首行说明检查的设备, 每一列说明从每个检查设备数据文件提取的数据类别. \n",
    "\n",
    "|HRT|\thumphrey|\n",
    "|:--|:--|\n",
    "|DOB\t|DOB|\n",
    "|sex\t|MD|\n",
    "|date\t|data|\n",
    "|Asymmetry_data\t|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* JSON字典: \n",
    "每种设备的JSON说明文件所在的位置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-14T09:10:39.657501Z",
     "start_time": "2018-05-14T09:10:39.624566Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_class_and_category_df(class_path,class_fname,category_path,category_fname,jpath):\n",
    "    #读取分类文件\n",
    "#     class_path=os.path.join('..','testdata')\n",
    "#     class_fname=\"class.csv\"\n",
    "    classfilename=os.path.join(class_path,class_fname)\n",
    "    class_df=pd.read_csv(classfilename)\n",
    "\n",
    "    # 读取数据类别选取文件\n",
    "#     category_path=class_path\n",
    "#     category_fname=\"analysis_category.csv\"\n",
    "    category_filename=os.path.join(category_path,category_fname)\n",
    "    category_df=pd.read_csv(category_filename)\n",
    "\n",
    "    # jsonfile_dict:\n",
    "#     jpath=os.path.join(\"..\",\"medical_device_data\")\n",
    "    jname_dict={\"HRT\": os.path.join(jpath,\"HRT.json\"),\n",
    "                \"humphrey\": os.path.join(jpath,\"humphrey.json\"),\n",
    "                \"GrandSeikoWAM5500\": os.path.join(jpath,\"GrandSeikoWAM5500.json\"),\n",
    "                \"pentacam\": os.path.join(jpath,\"pentacam.json\"),\n",
    "                \"sirius\": os.path.join(jpath,\"sirius.json\")\n",
    "               }\n",
    "    return class_df,category_df,jname_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 展开数据\n",
    "每个数据应当展开成一列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-14T09:10:39.674315Z",
     "start_time": "2018-05-14T09:10:39.666831Z"
    }
   },
   "outputs": [],
   "source": [
    "def flatten_data(data):\n",
    "    data_list=[]\n",
    "    for v in data.values():\n",
    "        data_list+=(v.values.flatten().tolist())\n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-14T06:34:04.713337Z",
     "start_time": "2018-05-14T06:34:04.692622Z"
    }
   },
   "source": [
    "## 取得数据集\n",
    "数据集包括两部分, X和Y. \n",
    "\n",
    "* Y是标签数据, 也就是class.csv中class的那一列数据. \n",
    "* X是每个数据文件中蕴含的所有数据, 排成一列. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-14T09:16:03.680263Z",
     "start_time": "2018-05-14T09:16:03.598625Z"
    }
   },
   "outputs": [],
   "source": [
    "from data_cleaner_WAM5500 import clean_WAM5500_data\n",
    "def identify(data):\n",
    "    return data\n",
    "\n",
    "def get_data(class_path,class_fname,category_path,category_fname,jpath):\n",
    "    class_df,category_df,jname_dict= get_class_and_category_df(class_path,class_fname,category_path,category_fname,jpath)\n",
    "    machine_list=class_df.columns[1:]\n",
    "    X_data=[]\n",
    "    \n",
    "    cleaner_dict={\"GrandSeikoWAM5500\": clean_WAM5500_data,\n",
    "                 \"HRT\": identify,\n",
    "                \"humphrey\": identify,\n",
    "                \"GrandSeikoWAM5500\": identify,\n",
    "                \"pentacam\": identify,\n",
    "                \"sirius\": identify,}\n",
    "    \n",
    "    for idx in range(len(class_df)):\n",
    "#         class_data=class_df.loc[idx,\"class\"]\n",
    "        row_data=[]\n",
    "        for machine in machine_list:\n",
    "        # machine=\"HRT\"\n",
    "            dname=class_df.loc[idx,machine]\n",
    "            datafilename=os.path.join(dpath,dname)\n",
    "            category=list(category_df[machine].dropna().values)\n",
    "            jsonfilename=jname_dict[machine]\n",
    "            mdata=read_medical_data(datafilename,category,jsonfilename)\n",
    "            # 此处应当分别调用各种类别数据的清洁器\n",
    "            mdata=cleaner_dict[machine](mdata)\n",
    "            \n",
    "            row_data+=flatten_data(mdata)\n",
    "        X_data.append(row_data)\n",
    "    X=pd.DataFrame(X_data).T\n",
    "    y=class_df[\"class\"]\n",
    "    return X,y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-14T09:16:04.358807Z",
     "start_time": "2018-05-14T09:16:04.152822Z"
    }
   },
   "outputs": [],
   "source": [
    "if __name__==\"__main__\":\n",
    "    data_path=os.path.join('..','testdata')\n",
    "    jpath=os.path.join(\"..\",\"medical_device_data\")\n",
    "    X,y=get_data(data_path,\"class.csv\",data_path,\"analysis_category.csv\",jpath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-14T09:16:11.124027Z",
     "start_time": "2018-05-14T09:16:11.114930Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    OS_glaucoma\n",
       "1    OD_glaucoma\n",
       "2      OS_normal\n",
       "3      OD_normal\n",
       "Name: class, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "26px",
    "width": "254px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
