{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 提取HRT数据\n",
    "## 设定文件路径参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__==\"__main__\":\n",
    "    input_path='../../testdata/HRT'\n",
    "    output_path=\"../../testdata/HRT\"\n",
    "    fname=\"HRT.pdf\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入依赖包"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在使用notebook.azure.com在线运行时, 由于默认没有安装pdfminer.six这个包, 所以在首次运行时需要安装, 已经将安装代码加入到下面导入依赖包的代码内, 因此首次运行时速度会较慢. \n",
    "\n",
    "同时, 在使用notebook.azure.com在线运行时, 服务器端不会保存曾经安装过的包, 因此在1小时没有操作之后, 服务器会关闭, 再次打开时就已经丢失了之前安装的包, 相当于首次运行. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import os.path\n",
    "import io\n",
    "import re\n",
    "import pandas as pd\n",
    "from pandas import Series,DataFrame\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "\n",
    "try:\n",
    "    from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "    from pdfminer.pdfpage import PDFPage\n",
    "    from pdfminer.converter import XMLConverter, HTMLConverter, TextConverter\n",
    "    from pdfminer.layout import LAParams\n",
    "except:\n",
    "    !conda install pdfminer.six --yes\n",
    "    from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "    from pdfminer.pdfpage import PDFPage\n",
    "    from pdfminer.converter import XMLConverter, HTMLConverter, TextConverter\n",
    "    from pdfminer.layout import LAParams\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 读取原始数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdfparser(input_path,fname):\n",
    "    filename=os.path.join(input_path,fname)\n",
    "    fp = open(filename, 'rb')\n",
    "    rsrcmgr = PDFResourceManager()\n",
    "    retstr = io.StringIO()\n",
    "    codec = 'utf-8'\n",
    "    laparams = LAParams()\n",
    "    device = TextConverter(rsrcmgr, retstr, codec=codec, laparams=laparams)\n",
    "    # Create a PDF interpreter object.\n",
    "    interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "    # Process each page contained in the document.\n",
    "\n",
    "    for page in PDFPage.get_pages(fp):\n",
    "        interpreter.process_page(page)\n",
    "        txt_string =  retstr.getvalue()\n",
    "\n",
    "    return txt_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 提取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_df(txt_str, pattern, data_index):\n",
    "    info=list( re.findall(pattern,txt_str)[0])\n",
    "    return DataFrame(info, index=data_index)\n",
    "def common_pattern():\n",
    "    global sth,float_number,p_hospital,p_name,p_DOB,p_ID,p_exam,p_diagnosis,p_comment,p_report\n",
    "    global p_OCT_Q,p_sex,p_radius,p_T,p_N,p_S,p_I,p_ISNT\n",
    "    sth=\"([\\s\\S]*?)\"\n",
    "    float_number=\"(\\-*\\d*\\.*\\d+?)\"\n",
    "    p_hospital=p_name=p_DOB=p_ID=p_exam=p_diagnosis=p_comment=p_report=sth\n",
    "    p_OCT_Q=\"\\s(\\d+)\\s\"\n",
    "    p_sex=\"([F|M])\"\n",
    "    p_radius=p_T=p_N=p_S=p_I=float_number\n",
    "    p_ISNT= \"T\"+p_T+\\\n",
    "            \"N\"+p_N+\\\n",
    "            \"S\"+p_S+\\\n",
    "            \"I\"+p_S+\\\n",
    "            \"G\"+float_number+\"\\((\\d+)\\)\"+\\\n",
    "            \"T\"+float_number+\"\\((\\d+)\\)\"+\\\n",
    "            \"TS\"+float_number+\"\\((\\d+)\\)\"+\\\n",
    "            \"TI\"+float_number+\"\\((\\d+)\\)\"+\\\n",
    "            \"N\"+float_number+\"\\((\\d+)\\)\"+\\\n",
    "            \"NS\"+float_number+\"\\((\\d+)\\)\"+\\\n",
    "            \"NI\"+float_number+\"\\((\\d+)\\)\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_basic_info(txt_str):\n",
    "    basic_info_pattern=p_hospital+\\\n",
    "        \"Patient:\"+p_name+\\\n",
    "        \"DOB:\"+p_DOB+\\\n",
    "        \"Sex:\"+p_sex+\\\n",
    "        \"Patient ID:\"+p_ID+\\\n",
    "        \"Exam.:\"+p_exam+\\\n",
    "        \"Diagnosis:\"+p_diagnosis+\\\n",
    "        \"Comment:\"+p_comment+\\\n",
    "        \"Software Version:\"+\"[\\s\\S]*\"+\"Report OU\"+\\\n",
    "        p_report+\\\n",
    "        \"OS200\"\n",
    "    basic_info_index=[\"Hospital\",\n",
    "        \"Patient\",\n",
    "        \"DOB\",\n",
    "        \"Sex\",\n",
    "        \"Patient_ID\",\n",
    "        \"Exam_date\",\n",
    "        \"Diagnosis\",\n",
    "        \"Comment\",\n",
    "        \"Report\"]\n",
    "    return extract_df(txt_str, basic_info_pattern, basic_info_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Asymmetry_data(txt_str):\n",
    "    Asymmetry_pattern=\"AsymmetryOD - OS\"+\\\n",
    "        \"T\"+p_T+\\\n",
    "        \"N\"+p_N+\\\n",
    "        \"S\"+p_S+\\\n",
    "        \"I\"+p_I+\\\n",
    "        \"G\"+float_number+\\\n",
    "        \"T\"+float_number+\\\n",
    "        \"TS\"+float_number+\\\n",
    "        \"TI\"+float_number+\\\n",
    "        \"N\"+float_number+\\\n",
    "        \"NS\"+float_number+\\\n",
    "        \"NI\"+float_number+\\\n",
    "        \"[\\s\\S]*\"+\\\n",
    "        \"TMPSUPNASINFTMPRNFL Thickness\"\n",
    "    Asymmetry_index=[\"Asymmetry_T\", \n",
    "        \"Asymmetry_N\",\n",
    "        \"Asymmetry_S\",\n",
    "        \"Asymmetry_I\",\n",
    "        \"Asymmetry_G\",\n",
    "        \"Asymmetry_T\",\n",
    "        \"Asymmetry_TS\",\n",
    "        \"Asymmetry_TI\",\n",
    "        \"Asymmetry_N\",\n",
    "        \"Asymmetry_NS\",\n",
    "        \"Asymmetry_NI\"]\n",
    "    return extract_df(txt_str, Asymmetry_pattern, Asymmetry_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ISNT_data(txt_str):\n",
    "    OS_ISNT_pattern=\"OS200\"+'[\\s\\S]*?'+p_radius+\"\\-*\\d*\\.*\\d*?\"+\\\n",
    "        \"IR 30° ART \\[HS\\]\"+\"ILMILM\"+\"RNFLRNFL200\"+'[\\s\\S]*?'+\\\n",
    "        \"OCT Q:\"+p_OCT_Q+\\\n",
    "        \"\\[HS\\]TMPSUPNASINFTMPRNFL Thickness\"+'[\\s\\S]*?'+\\\n",
    "        \"Position\"+'[\\s\\S]*?'+\"\\d+\"+\\\n",
    "        p_ISNT+\\\n",
    "        \"Classification OS\"\n",
    "    OD_ISNT_pattern=OS_ISNT_pattern.replace(\"OS\",\"OD\")\n",
    "    OS_ISNT_index=[        \n",
    "        \"OS_radius\",\n",
    "        \"OS_OCT Q\",\n",
    "        \"OS_T\",\n",
    "        \"OS_N\",\n",
    "        \"OS_S\",\n",
    "        \"OS_I\",\n",
    "        \"OSR_G\",\n",
    "        \"OSR_G_ref\",\n",
    "        \"OSR_T\",\n",
    "        \"OSR_T_ref\",\n",
    "        \"OSR_TS\",\n",
    "        \"OSR_TS_ref\",\n",
    "        \"OSR_TI\",\n",
    "        \"OSR_TI_ref\",\n",
    "        \"OSR_N\",\n",
    "        \"OSR_N_ref\",\n",
    "        \"OSR_NS\",\n",
    "        \"OSR_NS_ref\",\n",
    "        \"OSR_NI\",\n",
    "        \"OSR_NI_ref\",]\n",
    "    OD_ISNT_index=[OS.replace(\"OS\",\"OD\") for OS in OS_ISNT_index]\n",
    "    OS_ISNT_data=extract_df(txt_str, OS_ISNT_pattern, OS_ISNT_index)\n",
    "    OD_ISNT_data=extract_df(txt_str, OD_ISNT_pattern, OD_ISNT_index)\n",
    "    return pd.concat([OS_ISNT_data,OD_ISNT_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Classification_data(txt_str):\n",
    "    Classification_pattern=\"Classification OS\"+sth+\\\n",
    "        \"OD200\"+\"[\\s\\S]*?\"+\\\n",
    "        \"Classification OD\"+sth+\\\n",
    "        \"Asymmetry\"\n",
    "    Classification_index=[\"Classification OS\",\"Classification OD\"]\n",
    "    return extract_df(txt_str, Classification_pattern,Classification_index)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 合并"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_HRT_df(input_path,fname):\n",
    "    txt_str=pdfparser(input_path,fname)\n",
    "    common_pattern()\n",
    "    basic_info=get_basic_info(txt_str)\n",
    "    ISNT_data=get_ISNT_data(txt_str)\n",
    "    Asymmetry_data=get_Asymmetry_data(txt_str)\n",
    "    Classification_data=get_Classification_data(txt_str)\n",
    "    df=pd.concat([basic_info,ISNT_data,Asymmetry_data,Classification_data])\n",
    "    df.columns=['Value']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 保存数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_out_name(output_path,fname):\n",
    "    return os.path.join(output_path,\"csv\", \"{}.csv\".format(os.path.splitext(fname)[0]))\n",
    "\n",
    "def save_to_csv(df,output_path,fname):\n",
    "    df.to_csv(get_out_name(output_path,fname),sep=',',header=False)\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 处理目录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_folder(input_path,output_path):\n",
    "    pdffiles = [name for name in os.listdir(input_path)\n",
    "            if name.endswith('.pdf')]\n",
    "\n",
    "    df_list=[]\n",
    "    for fname in pdffiles:\n",
    "        print(\"Convert PDF file {} to CSV\".format(fname))\n",
    "        df=get_HRT_df(input_path,fname)\n",
    "        save_to_csv(df,output_path,fname)\n",
    "        print(\"done\")\n",
    "\n",
    "        df_list.append(df)\n",
    "    print(\"Merge together\")\n",
    "    df_merged = reduce(lambda left,right: pd.merge(left,right,left_index=True,right_index=True), df_list)\n",
    "    save_to_csv(df_merged,output_path,\"together.csv\")\n",
    "    print(\"done\")\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convert PDF file HRT.pdf to CSV\n",
      "done\n",
      "Convert PDF file HRT的副本 3.pdf to CSV\n",
      "done\n",
      "Convert PDF file HRT的副本.pdf to CSV\n",
      "done\n",
      "Convert PDF file HRT的副本 2.pdf to CSV\n",
      "done\n",
      "Merge together\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    convert_folder(input_path,output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "180px",
    "width": "254px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
